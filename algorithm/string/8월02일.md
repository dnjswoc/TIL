# 8월 2일 수업 내용 정리
## 문자의 표현
- 컴퓨터에서의 문자표현
    - 글자 A를 메모리에 저장하는 방법에 대해서 생각해보자.
    - 물론 칼로 A라는 글자를 새기는 방식은 아닐 것이다. 메모리는 숫자만을 저장할 수 있기 때문에 A라는 글자의 모양 그대로 비트맵으로 저장하는 방법을 사용하지 않는 한(이 방법은 메모리 낭비가 심하다) 각 문자에 대해서 대응되는 숫자를 정해 놓고 이것을 메모리에 저장하는 방법이 사용될 것이다.
    - 영어가 대소문자 합쳐서 52자 이므로 6(64가지)비트면 모두 표현할 수 있다.(ex. 000000 -> 'a', 000001 -> 'b')

- 그런데 네트워크가 발전되기 전 미국의 각 지역 별로 코드체계를 정해 놓고 사용했지만
- 네트워크(인터넷 : 인터넷은 미국에서 발전했다)이 발전하면서 서로 간에 정보를 주고 받을 때 정보를 달리 해석한다는 문제가 생겼다.
- 그래서 혼동을 피하기 위해 표준안을 만들기로 했다.
- 바로 이러한 목적으로 1967년, 미국에서 ASCII(American Standard Cod for Information Interchange)라는 문자 인코딩 표준이 제정되었다.
- ASCII는 7-bit 인코딩으로 128문자를 표현하며 33개의 출력 불가능한 제어 문자들과 공백을 비롯한 95개의 출력 가능한 문자들로 이루어져있다.
- 확장 아스키는 표준 문자 이외의 악센트 문자, 도형 문자, 특수 문자, 특수 기호 등 부가적인 문자를 128개 추가할 수 있게 하는 부호이다.
    - 표준 아스키는 7-bit를 사용하여 문자를 표현하는 데 비해 확장 아스키는 18Byte 내의 8-bit를 모두 사용함으로써 추가적인 문자를 표현할 수 있다.
    - 컴퓨터 생산자와 소프트웨어 개발자가 여러 가지 다양한 문자에 할당할 수 있도록 하고 있다. 이렇게 할당된 확장 부호는 표준 아스키와 같이 서로 다른 프로그램이나 컴퓨터 사이에 교환되지 못한다.
    - 그러므로 표준 아스키는 마이크로컴퓨터 하드웨어 및 소프트웨어 사이에서 세계적으로 통용되는 데 비해, 확장 아스키는 프로그램이나 컴퓨터 또는 프린터가 그것을 해독할 수 있도록 설계되어 있어야만 올바로 해독될 수 있다.

- 오늘 날 대부분의 컴퓨터는 문자를 읽고 쓰는데 ASCII형식을 사용한다.
- 그런데 컴퓨터가 발전하면서 미국 뿐 아니라 각 나라에서도 컴퓨터가 발전했으며 각 국가들은 자국의 문자를 표현하기 위하여 코드체계를 만들어서 사용하게 되었다.
    - 우리나라도 아주 오래된 이야기지만 한글 코드체계를 만들어 사용했고 조합형, 완성형 두 종류를 가지고 있었다.

- 인터넷이 전 세계로 발전하면서 ASCII를 만들었을 때의 문제와 같은 문제가 국가 간에 정보를 주고 받을 때 발생했다.
- 자국의 코드체계를 타 국가가 가지고 있지 않으면 정보를 잘못 해석할 수 밖에 없었다.
- 그래서 다국어 처리를 위해 표준을 마련했다. 이를 유티코드라고 한다.

- 유니코드도 다시 Character Set으로 분류된다.
    - UCS-2(Universal Character Set 2)
    - UCS-4(Universal Character Set 4)
    - 유니코드를 저장하는 변수의 크기를 정의
    - 그러나, 바이트 순서에 대해서 표준화하지 못했음
    - 다시 말해 파일을 인식 시 이 파일이 UCS-2, UCS-4인지 인식하고 각 경우를 구분해서 모두 다르게 구현해야 하는 문제 발생
    - 그래서 유니코드의 적당한 외부 인코딩이 필요하게 되었다.

- big-endian, little endian
- 유니코드 인코딩(UTF : Unicode Transformation Format)
    - UTF-8
    - UTF-16
    - UTF-32

## 문자열



