{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **🔍 Objectives**\n",
    "\n",
    "### **1. 실습 개요**  \n",
    "- 🔎 **데이터 확인하기**  \n",
    "- ❓ **결측치가 모델에 미치는 영향 확인**  \n",
    "- ⚠️ **이상치가 모델에 미치는 영향 확인**  \n",
    "\n",
    "---\n",
    "\n",
    "### **2. 실습 진행 목적 및 배경**  \n",
    "- 데이터에 **결측치**와 **이상치**가 존재할 때, 머신러닝 모델에 미치는 부정적 영향을 파악함으로써, **데이터 품질 관리의 중요성**을 이해합니다.  \n",
    "- 이를 통해 **수집한 데이터의 품질**을 관리하고 유지하는 방법을 배우며, 데이터 처리와 관련된 기본 지침을 익힐 수 있습니다.  \n",
    "\n",
    "---\n",
    "\n",
    "### **3. 실습 수행으로 얻어갈 수 있는 역량**  \n",
    "- **Random Forest** 사용법\n",
    "- **Logistic Regression** 사용법  \n",
    "\n",
    "---\n",
    "\n",
    "### **4. 데이터셋 개요 및 저작권 정보**\n",
    "\n",
    "#### **📁 Titanic 데이터셋**\n",
    "- **데이터 설명**:  \n",
    "  - 타이타닉 호 침몰 사고에서의 **승객 정보**를 포함하고 있으며, **생존 여부 예측 문제**를 중심으로 분석하는 데 활용됩니다.\n",
    "  - 수치형, 범주형 데이터를 모두 포함하고 있고 결측치, 이상치 등이 포함되어 있어 데이터 분석에 활용하기 좋습니다.\n",
    "- **데이터셋 저작권**: Apache 2.0  \n",
    "- **컬럼명 설명**:  \n",
    "  - `survived`: 생존 여부 (0: 사망, 1: 생존)  \n",
    "  - `pclass`: 객실 등급 (1: 1등급, 2: 2등급, 3: 3등급)  \n",
    "  - `sex`: 성별 (`male`: 남성, `female`: 여성)  \n",
    "  - `age`: 승객 나이 (결측치 포함)  \n",
    "  - `sibsp`: 함께 탑승한 형제자매 또는 배우자의 수  \n",
    "  - `parch`: 함께 탑승한 부모 또는 자녀의 수  \n",
    "  - `fare`: 티켓 요금  \n",
    "  - `embarked`: 탑승한 항구 (`C`: Cherbourg, `Q`: Queenstown, `S`: Southampton)  \n",
    "  - `class`: 객실 등급 (1st, 2nd, 3rd로 표현)  \n",
    "  - `who`: 승객 구분 (`man`: 남성, `woman`: 여성, `child`: 어린이)  \n",
    "  - `adult_male`: 성인 남성 여부 (`True`: 성인, `False`: 성인 아님)  \n",
    "  - `deck`: 객실 위치 (결측치 포함)  \n",
    "  - `embark_town`: 탑승한 도시 (`C`, `Q`, `S`)  \n",
    "  - `alive`: 생존 여부 (`yes`: 생존, `no`: 사망)  \n",
    "  - `alone`: 혼자 탑승 여부 (`True`: 혼자, `False`: 동반)  \n",
    "\n",
    "---\n",
    "\n",
    "### **5. 실습 핵심 내용**\n",
    "1. 먼저 데이터를 불러오고 데이터셋이 어떻게 생겼는지 확인하는 방법을 익힙니다.\n",
    "2. 데이터에 결측치가 있을 때 모델 훈련에 어떤 영향을 미치는지 확인합니다.\n",
    "3. 데이터에 이상치가 있을 때 모델 훈련에 어떤 영향을 미치는지 확인합니다,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Prerequisites**\n",
    "\n",
    "```\n",
    "numpy == 1.26.4\n",
    "pandas == 2.2.2\n",
    "seaborn == 0.13.2\n",
    "matplotlib == 3.8.0\n",
    "sklearn == 1.5.2\n",
    "missingno == 0.5.2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise Overview**\n",
    "제공된 데이터셋을 바탕으로 머신러닝 모델 2가지(Random Forest, Logistic Regression)를 실행해 테스트합니다.\n",
    "\n",
    "**1. 데이터 확인하기**\n",
    "- 데이터를 불러오고 데이터가 어떻게 생겼는지 간단히 확인하는 방법과 시각화 하는 방법을 배웁니다.\n",
    "\n",
    "**2. 결측치가 모델에 미치는 영향 확인**\n",
    "- 데이터에 결측치가 있을 때 모델 훈련에 어떠한 영향을 미치는지 정확도를 비교하여 확인합니다.\n",
    "- 결측치가 있을 때, 결측치를 제거했을 때, 결측치를 평균값으로 대체했을 때 각각의 결과를 비교합니다.\n",
    "\n",
    "**3. 이상치가 모델에 미치는 영향 확인**\n",
    "- 이상치를 어떤 기준으로 정의하는지 확인합니다.\n",
    "- 데이터에 이상치가 있을 때 모델 훈련에 어떠한 영향을 미치는지 확인합니다.\n",
    "- 이상치가 있을 때, 이상치를 제거했을 때, 이상치를 평균값으로 대체했을 때 각각의 결과를 비교합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 확인하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 라이브러리 임포트\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# 나눔고딕 폰트 설치\n",
    "!apt-get -qq install fonts-nanum\n",
    "\n",
    "# 설치된 폰트를 Matplotlib에 적용\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib as mpl\n",
    "\n",
    "# 나눔고딕 폰트 경로 가져오기\n",
    "font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\n",
    "font_prop = fm.FontProperties(fname=font_path)\n",
    "\n",
    "# Matplotlib에 폰트 설정\n",
    "mpl.rc('font', family=font_prop.get_name())\n",
    "\n",
    "# 한글 깨짐 방지 (음수 폰트 설정)\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# Titanic 데이터셋 로드\n",
    "titanic = sns.load_dataset('titanic')\n",
    "\n",
    "# 결과가 불필요하게 길어져 중요하지 않은 오류 문구를 제거하기 위해 넣은 코드입니다.\n",
    "import logging\n",
    "logging.getLogger('matplotlib.font_manager').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 데이터 요약해서 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 데이터셋 간단히 확인\n",
    "print(\"데이터셋의 첫 5행:\")\n",
    "print(titanic.head())\n",
    "\n",
    "print(\"\\n데이터셋 요약 정보:\")\n",
    "titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 통계 요약\n",
    "print(\"\\n수치형 데이터 통계 요약:\")\n",
    "print(titanic.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n범주형 데이터의 고유값 확인:\")\n",
    "for column in titanic.select_dtypes(include=['object', 'category']).columns:\n",
    "    print(f\"{column}의 고유값:\")\n",
    "    print(titanic[column].value_counts())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 데이터 시각화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 1. 생존 여부 분포\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(data=titanic, x='survived')\n",
    "plt.title(\"Survival Count (0 = Not Survived, 1 = Survived)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 2. 성별에 따른 생존 여부\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(data=titanic, x='sex', hue='survived')\n",
    "plt.title(\"Survival Count by Gender\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 3. 나이 분포\n",
    "plt.figure(figsize=(8, 5))\n",
    "# kde : 데이터의 밀도를 추정하는 곡선 추가. bins : 구간을 나눌 개수\n",
    "sns.histplot(data=titanic, x='age', kde=True, bins=30)\n",
    "plt.title(\"Age Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 4. 클래스에 따른 생존 여부\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(data=titanic, x='class', hue='survived')\n",
    "plt.title(\"Survival Count by Passenger Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 5. 요금 분포\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.boxplot(data=titanic, x='class', y='fare', hue='survived')\n",
    "plt.title(\"Fare Distribution by Class and Survival\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 결측치가 모델에 미치는 영향 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 데이터 내 결측치 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"=== 결측치 개수 확인 ===\")\n",
    "missing_data = titanic.isnull().sum()\n",
    "print(missing_data[missing_data > 0])\n",
    "\n",
    "total_missing = titanic.isnull().sum().sum()\n",
    "print(f\"\\n전체 데이터셋에서의 결측치 개수: {total_missing}\")\n",
    "\n",
    "missing_per_column = titanic.isnull().sum()\n",
    "print(\"\\n열별 결측치 개수:\")\n",
    "print(missing_per_column[missing_per_column > 0])\n",
    "\n",
    "print(\"\\n열별 결측치 비율 (%):\")\n",
    "print((missing_per_column[missing_per_column > 0] / len(titanic) * 100).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 결측치 시각화하기\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 6))\n",
    "msno.matrix(titanic)\n",
    "plt.title(\"Missing Values Visualization\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 그림에서 흰색 가로 선이 결측치를 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 결측치 처리 - 제거(drop), 평균값으로 대체(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "def preprocess_data_missing(data, fill_method=None):\n",
    "    df = data.copy()\n",
    "\n",
    "    # 성별, 탑승 항구 등 범주형 변수 인코딩\n",
    "    df['sex'] = df['sex'].map({'male': 0, 'female': 1})  # 성별을 0과 1로 변환\n",
    "    df['embarked'] = df['embarked'].map({'C': 0, 'Q': 1, 'S': 2})  # 탑승 항구를 0, 1, 2로 변환\n",
    "    df['embarked'] = df['embarked'].fillna(df['embarked'].mode()[0])  # 탑승 항구 결측값 대체\n",
    "\n",
    "    # 결측값 처리 (선택적으로)\n",
    "    if fill_method == 'drop':\n",
    "        df = df.dropna()\n",
    "    elif fill_method == 'mean':\n",
    "        df['age'] = df['age'].fillna(df['age'].mean())\n",
    "        df['fare'] = df['fare'].fillna(df['fare'].mean())\n",
    "    else:\n",
    "        pass  # 결측값 있는 그대로 유지\n",
    "\n",
    "    # 필요한 컬럼 선택\n",
    "    df = df[['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 결측치가 모델에 미치는 영향 - Random Forest\n",
    "- **Random Forest**는 앙상블(Ensemble) 학습 기법의 하나로, 여러 개의 결정 트리(Decision Tree)를 결합하여 더 나은 예측 성능을 얻는 방법입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 모델 학습 및 평가\n",
    "def random_forest_missing(data):\n",
    "    # 'survived' 열을 타겟 변수(y)로 설정하고, 나머지 열을 특성(X)으로 설정\n",
    "    X = data.drop(columns='survived')  # 타겟 변수 'survived'를 제외한 특성 데이터\n",
    "    y = data['survived']  # 타겟 변수 'survived' 선택\n",
    "\n",
    "    # 데이터를 훈련 세트와 테스트 세트로 분리 (훈련 80%, 테스트 20%)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Random Forest 분류기 모델 생성\n",
    "    model = RandomForestClassifier(random_state=42)  # 무작위성을 제어하기 위해 random_state 설정\n",
    "    model.fit(X_train, y_train)  # 훈련 데이터를 사용하여 모델 학습\n",
    "\n",
    "    # 테스트 데이터를 사용하여 예측 수행\n",
    "    y_pred = model.predict(X_test)  # 모델로 예측\n",
    "\n",
    "    # 예측 결과와 실제 값(y_test)을 비교하여 정확도 계산\n",
    "    accuracy = accuracy_score(y_test, y_pred)  # 정확도 계산\n",
    "    return accuracy  # 정확도를 반환\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결측치를 그대로 뒀을 때, 제거했을 때, 평균값으로 대체했을 때 성능(정확도) 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 각 결측치 처리 방법에 따른 성능 비교\n",
    "methods = ['original', 'drop', 'mean']\n",
    "results = {}\n",
    "\n",
    "for method in methods:\n",
    "    if method == 'original':\n",
    "        preprocessed_data = preprocess_data_missing(titanic)  # 결측치 처리 없이\n",
    "    else:\n",
    "        preprocessed_data = preprocess_data_missing(titanic, fill_method=method)\n",
    "\n",
    "    # 결측치가 있는 데이터는 제거 후 모델 학습\n",
    "    if method == 'original':\n",
    "        preprocessed_data = preprocessed_data.dropna(subset=['age', 'fare'])\n",
    "\n",
    "    accuracy = random_forest_missing(preprocessed_data)\n",
    "    results[method] = accuracy\n",
    "\n",
    "\n",
    "# 결과 출력\n",
    "print(\"=== 결측치 처리 방법에 따른 Random Forest 모델 성능 ===\")\n",
    "for method, acc in results.items():\n",
    "    print(f\"{method.capitalize()} 처리: Accuracy = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 결측치를 제거하는 것보다 평균값으로 대체할 때 예측 성능이 향상됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 결측치가 모델에 미치는 영향 - Logistic Regression\n",
    "- Logistic Regression은 데이터가 어떤 범주에 속할 확률을 정하고 가능성이 더 높은 범주에 속하는 것으로 분류하는 알고리즘입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "titanic = sns.load_dataset('titanic')\n",
    "\n",
    "def detect_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)  # 1분위수\n",
    "    Q3 = df[column].quantile(0.75)  # 3분위수\n",
    "    IQR = Q3 - Q1  # IQR 계산\n",
    "    lower_bound = Q1 - 1.5 * IQR  # 하한\n",
    "    upper_bound = Q3 + 1.5 * IQR  # 상한\n",
    "    return (df[column] < lower_bound) | (df[column] > upper_bound)\n",
    "\n",
    "\n",
    "def logistic_regression_missing(data):\n",
    "    # 'survived' 열을 타겟 변수(y)로 설정하고, 나머지 열을 특성(X)으로 설정\n",
    "    X = data.drop(columns='survived')  # 타겟 변수 'survived'를 제외한 특성 데이터\n",
    "    y = data['survived']  # 타겟 변수 'survived' 선택\n",
    "\n",
    "    # 데이터를 훈련 세트와 테스트 세트로 분리 (훈련 80%, 테스트 20%)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Logistic Regression 모델 생성 (최대 반복 횟수를 1000으로 설정하여 수렴을 보장)\n",
    "    model = LogisticRegression(max_iter=1000, random_state=42)  # 무작위성을 제어하기 위해 random_state 설정\n",
    "    model.fit(X_train, y_train)  # 훈련 데이터를 사용하여 모델 학습\n",
    "\n",
    "    # 테스트 데이터를 사용하여 예측 수행\n",
    "    y_pred = model.predict(X_test)  # 모델로 예측\n",
    "\n",
    "    # 예측 결과와 실제 값(y_test)을 비교하여 정확도 계산\n",
    "    accuracy = accuracy_score(y_test, y_pred)  # 정확도 계산\n",
    "    return accuracy  # 정확도를 반환\n",
    "\n",
    "\n",
    "# 각 결측값 처리 방법에 따른 성능 비교\n",
    "methods = ['original', 'drop', 'mean']\n",
    "results = {}\n",
    "\n",
    "\n",
    "for method in methods:\n",
    "    if method == 'original':\n",
    "        preprocessed_data = preprocess_data_missing(titanic)  # 결측값 처리 없이\n",
    "    else:\n",
    "        preprocessed_data = preprocess_data_missing(titanic, fill_method=method)\n",
    "\n",
    "    # 결측값이 있는 데이터는 제거 후 모델 학습\n",
    "    if method == 'original':\n",
    "        preprocessed_data = preprocessed_data.dropna(subset=['age', 'fare'])\n",
    "\n",
    "    accuracy = logistic_regression_missing(preprocessed_data)\n",
    "    results[method] = accuracy\n",
    "\n",
    "# 결과 출력\n",
    "print(\"=== 결측값 처리 방법에 따른 Logistic Regression 모델 성능 ===\")\n",
    "for method, acc in results.items():\n",
    "    print(f\"{method.capitalize()} 처리: Accuracy = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 결측치를 제거하는 것보다 평균값으로 대체할 때 예측 성능이 향상됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 이상치가 모델에 미치는 영향 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 이상치 확인\n",
    "\n",
    "**이상치(Outlier)**\n",
    "데이터의 1분위수를 Q1, 3분위수를 Q3라 하고 Q3-Q1을 IQR이라 합니다.\n",
    "\n",
    "이 때 Q1 - 1.5 * IQR보다 낮은 값과 Q3 + 1.5 * IQR 보다 큰 값들을 이상치라 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# age 컬럼의 이상치 시각화\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(y='age', data=titanic)\n",
    "plt.title('Age Column Boxplot')\n",
    "plt.show()\n",
    "\n",
    "# IQR을 이용한 이상치 탐지\n",
    "Q1 = titanic['age'].quantile(0.25)\n",
    "Q3 = titanic['age'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "outliers = titanic[(titanic['age'] < Q1 - 1.5 * IQR) | (titanic['age'] > Q3 + 1.5 * IQR)]\n",
    "print(f\"\\nage 컬럼에서 발견된 이상치 개수: {outliers.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 이상치 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def handle_outliers(df, method):\n",
    "    # 'age'와 'fare' 컬럼에서 이상치를 처리\n",
    "    for column in ['age', 'fare']:  # 수치형 변수인 'age'와 'fare'만 처리\n",
    "        outliers = detect_outliers(df, column)  # 'detect_outliers' 함수를 사용하여 이상치 인덱스 탐지\n",
    "        if method == 'remove':  # 이상치를 제거하는 방법\n",
    "            df = df[~outliers]  # 이상치가 포함된 행을 제거\n",
    "        elif method == 'mean':  # 이상치를 평균값으로 대체하는 방법\n",
    "            df.loc[outliers, column] = df[column].mean()  # 이상치 값을 해당 컬럼의 평균으로 대체\n",
    "    return df  # 이상치 처리가 완료된 데이터프레임 반환\n",
    "\n",
    "def preprocess_data_outlier(data, outlier_method=None):\n",
    "    # 데이터프레임을 복사하여 원본 데이터를 수정하지 않도록 함\n",
    "    df = data.copy()\n",
    "\n",
    "    # 범주형 변수 인코딩\n",
    "    df['sex'] = df['sex'].map({'male': 0, 'female': 1})  # 'male'을 0, 'female'을 1로 매핑\n",
    "    df['embarked'] = df['embarked'].map({'C': 0, 'Q': 1, 'S': 2})  # 'C', 'Q', 'S'를 각각 0, 1, 2로 매핑\n",
    "    df['embarked'] = df['embarked'].fillna(df['embarked'].mode()[0])  # 'embarked' 컬럼의 결측치를 최빈값으로 채움\n",
    "    df['age'] = df['age'].fillna(df['age'].mean())  # 'age' 컬럼의 결측치를 평균값으로 채움\n",
    "    df['fare'] = df['fare'].fillna(df['fare'].mean())  # 'fare' 컬럼의 결측치를 평균값으로 채움\n",
    "\n",
    "    # 이상치 처리 (선택적으로 처리)\n",
    "    if outlier_method:\n",
    "        df = handle_outliers(df, method=outlier_method)  # outlier_method가 주어지면 이상치 처리 함수 호출\n",
    "\n",
    "    # 분석에 사용할 변수 선택\n",
    "    df = df[['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']]  # 필요한 컬럼만 선택\n",
    "    return df  # 전처리된 데이터프레임 반환\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 이상치가 모델에 미치는 영향 - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 학습 및 평가\n",
    "titanic = sns.load_dataset('titanic')\n",
    "\n",
    "def random_forest_outlier(data):\n",
    "    X = data.drop(columns='survived')\n",
    "    y = data['survived']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "# 이상치 처리 방법에 따른 성능 비교\n",
    "methods = ['original', 'remove', 'mean']\n",
    "results = {}\n",
    "\n",
    "for method in methods:\n",
    "    if method == 'original':\n",
    "        preprocessed_data = preprocess_data_outlier(titanic)  # 이상치 처리 없이\n",
    "    else:\n",
    "        preprocessed_data = preprocess_data_outlier(titanic, outlier_method=method)\n",
    "\n",
    "    accuracy = random_forest_outlier(preprocessed_data)\n",
    "    results[method] = accuracy\n",
    "\n",
    "# 결과 출력\n",
    "print(\"=== 이상치 처리 방법에 따른 Random Forest 모델 성능 ===\")\n",
    "for method, acc in results.items():\n",
    "    print(f\"{method.capitalize()} 처리: Accuracy = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 이상치가 모델에 미치는 영향 - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 학습 및 평가\n",
    "titanic = sns.load_dataset('titanic')\n",
    "\n",
    "def logistic_regression_outlier(data):\n",
    "    X = data.drop(columns='survived')  # 독립 변수\n",
    "    y = data['survived']  # 종속 변수\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Logistic Regression 모델\n",
    "    model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "# 이상치 처리 방법에 따른 성능 비교\n",
    "methods = ['original', 'remove', 'mean']\n",
    "results = {}\n",
    "\n",
    "for method in methods:\n",
    "    if method == 'original':\n",
    "        preprocessed_data = preprocess_data_outlier(titanic)  # 이상치 처리 없이\n",
    "    else:\n",
    "        preprocessed_data = preprocess_data_outlier(titanic, outlier_method=method)\n",
    "\n",
    "    accuracy = logistic_regression_outlier(preprocessed_data)\n",
    "    results[method] = accuracy\n",
    "\n",
    "# 결과 출력\n",
    "print(\"=== 이상치 처리 방법에 따른 Logistic Regression 모델 성능 ===\")\n",
    "for method, acc in results.items():\n",
    "    print(f\"{method.capitalize()} 처리: Accuracy = {acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
