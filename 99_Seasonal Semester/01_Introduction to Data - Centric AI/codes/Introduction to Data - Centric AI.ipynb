{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **ğŸ” Objectives**\n",
    "\n",
    "### **1. ì‹¤ìŠµ ê°œìš”**  \n",
    "- ğŸ” **ë°ì´í„° í™•ì¸í•˜ê¸°**  \n",
    "- â“ **ê²°ì¸¡ì¹˜ê°€ ëª¨ë¸ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ í™•ì¸**  \n",
    "- âš ï¸ **ì´ìƒì¹˜ê°€ ëª¨ë¸ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ í™•ì¸**  \n",
    "\n",
    "---\n",
    "\n",
    "### **2. ì‹¤ìŠµ ì§„í–‰ ëª©ì  ë° ë°°ê²½**  \n",
    "- ë°ì´í„°ì— **ê²°ì¸¡ì¹˜**ì™€ **ì´ìƒì¹˜**ê°€ ì¡´ì¬í•  ë•Œ, ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì— ë¯¸ì¹˜ëŠ” ë¶€ì •ì  ì˜í–¥ì„ íŒŒì•…í•¨ìœ¼ë¡œì¨, **ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬ì˜ ì¤‘ìš”ì„±**ì„ ì´í•´í•©ë‹ˆë‹¤.  \n",
    "- ì´ë¥¼ í†µí•´ **ìˆ˜ì§‘í•œ ë°ì´í„°ì˜ í’ˆì§ˆ**ì„ ê´€ë¦¬í•˜ê³  ìœ ì§€í•˜ëŠ” ë°©ë²•ì„ ë°°ìš°ë©°, ë°ì´í„° ì²˜ë¦¬ì™€ ê´€ë ¨ëœ ê¸°ë³¸ ì§€ì¹¨ì„ ìµí ìˆ˜ ìˆìŠµë‹ˆë‹¤.  \n",
    "\n",
    "---\n",
    "\n",
    "### **3. ì‹¤ìŠµ ìˆ˜í–‰ìœ¼ë¡œ ì–»ì–´ê°ˆ ìˆ˜ ìˆëŠ” ì—­ëŸ‰**  \n",
    "- **Random Forest** ì‚¬ìš©ë²•\n",
    "- **Logistic Regression** ì‚¬ìš©ë²•  \n",
    "\n",
    "---\n",
    "\n",
    "### **4. ë°ì´í„°ì…‹ ê°œìš” ë° ì €ì‘ê¶Œ ì •ë³´**\n",
    "\n",
    "#### **ğŸ“ Titanic ë°ì´í„°ì…‹**\n",
    "- **ë°ì´í„° ì„¤ëª…**:  \n",
    "  - íƒ€ì´íƒ€ë‹‰ í˜¸ ì¹¨ëª° ì‚¬ê³ ì—ì„œì˜ **ìŠ¹ê° ì •ë³´**ë¥¼ í¬í•¨í•˜ê³  ìˆìœ¼ë©°, **ìƒì¡´ ì—¬ë¶€ ì˜ˆì¸¡ ë¬¸ì œ**ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ë¶„ì„í•˜ëŠ” ë° í™œìš©ë©ë‹ˆë‹¤.\n",
    "  - ìˆ˜ì¹˜í˜•, ë²”ì£¼í˜• ë°ì´í„°ë¥¼ ëª¨ë‘ í¬í•¨í•˜ê³  ìˆê³  ê²°ì¸¡ì¹˜, ì´ìƒì¹˜ ë“±ì´ í¬í•¨ë˜ì–´ ìˆì–´ ë°ì´í„° ë¶„ì„ì— í™œìš©í•˜ê¸° ì¢‹ìŠµë‹ˆë‹¤.\n",
    "- **ë°ì´í„°ì…‹ ì €ì‘ê¶Œ**: Apache 2.0  \n",
    "- **ì»¬ëŸ¼ëª… ì„¤ëª…**:  \n",
    "  - `survived`: ìƒì¡´ ì—¬ë¶€ (0: ì‚¬ë§, 1: ìƒì¡´)  \n",
    "  - `pclass`: ê°ì‹¤ ë“±ê¸‰ (1: 1ë“±ê¸‰, 2: 2ë“±ê¸‰, 3: 3ë“±ê¸‰)  \n",
    "  - `sex`: ì„±ë³„ (`male`: ë‚¨ì„±, `female`: ì—¬ì„±)  \n",
    "  - `age`: ìŠ¹ê° ë‚˜ì´ (ê²°ì¸¡ì¹˜ í¬í•¨)  \n",
    "  - `sibsp`: í•¨ê»˜ íƒ‘ìŠ¹í•œ í˜•ì œìë§¤ ë˜ëŠ” ë°°ìš°ìì˜ ìˆ˜  \n",
    "  - `parch`: í•¨ê»˜ íƒ‘ìŠ¹í•œ ë¶€ëª¨ ë˜ëŠ” ìë…€ì˜ ìˆ˜  \n",
    "  - `fare`: í‹°ì¼“ ìš”ê¸ˆ  \n",
    "  - `embarked`: íƒ‘ìŠ¹í•œ í•­êµ¬ (`C`: Cherbourg, `Q`: Queenstown, `S`: Southampton)  \n",
    "  - `class`: ê°ì‹¤ ë“±ê¸‰ (1st, 2nd, 3rdë¡œ í‘œí˜„)  \n",
    "  - `who`: ìŠ¹ê° êµ¬ë¶„ (`man`: ë‚¨ì„±, `woman`: ì—¬ì„±, `child`: ì–´ë¦°ì´)  \n",
    "  - `adult_male`: ì„±ì¸ ë‚¨ì„± ì—¬ë¶€ (`True`: ì„±ì¸, `False`: ì„±ì¸ ì•„ë‹˜)  \n",
    "  - `deck`: ê°ì‹¤ ìœ„ì¹˜ (ê²°ì¸¡ì¹˜ í¬í•¨)  \n",
    "  - `embark_town`: íƒ‘ìŠ¹í•œ ë„ì‹œ (`C`, `Q`, `S`)  \n",
    "  - `alive`: ìƒì¡´ ì—¬ë¶€ (`yes`: ìƒì¡´, `no`: ì‚¬ë§)  \n",
    "  - `alone`: í˜¼ì íƒ‘ìŠ¹ ì—¬ë¶€ (`True`: í˜¼ì, `False`: ë™ë°˜)  \n",
    "\n",
    "---\n",
    "\n",
    "### **5. ì‹¤ìŠµ í•µì‹¬ ë‚´ìš©**\n",
    "1. ë¨¼ì € ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê³  ë°ì´í„°ì…‹ì´ ì–´ë–»ê²Œ ìƒê²¼ëŠ”ì§€ í™•ì¸í•˜ëŠ” ë°©ë²•ì„ ìµí™ë‹ˆë‹¤.\n",
    "2. ë°ì´í„°ì— ê²°ì¸¡ì¹˜ê°€ ìˆì„ ë•Œ ëª¨ë¸ í›ˆë ¨ì— ì–´ë–¤ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "3. ë°ì´í„°ì— ì´ìƒì¹˜ê°€ ìˆì„ ë•Œ ëª¨ë¸ í›ˆë ¨ì— ì–´ë–¤ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Prerequisites**\n",
    "\n",
    "```\n",
    "numpy == 1.26.4\n",
    "pandas == 2.2.2\n",
    "seaborn == 0.13.2\n",
    "matplotlib == 3.8.0\n",
    "sklearn == 1.5.2\n",
    "missingno == 0.5.2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exercise Overview**\n",
    "ì œê³µëœ ë°ì´í„°ì…‹ì„ ë°”íƒ•ìœ¼ë¡œ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ 2ê°€ì§€(Random Forest, Logistic Regression)ë¥¼ ì‹¤í–‰í•´ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "**1. ë°ì´í„° í™•ì¸í•˜ê¸°**\n",
    "- ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ê³  ë°ì´í„°ê°€ ì–´ë–»ê²Œ ìƒê²¼ëŠ”ì§€ ê°„ë‹¨íˆ í™•ì¸í•˜ëŠ” ë°©ë²•ê³¼ ì‹œê°í™” í•˜ëŠ” ë°©ë²•ì„ ë°°ì›ë‹ˆë‹¤.\n",
    "\n",
    "**2. ê²°ì¸¡ì¹˜ê°€ ëª¨ë¸ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ í™•ì¸**\n",
    "- ë°ì´í„°ì— ê²°ì¸¡ì¹˜ê°€ ìˆì„ ë•Œ ëª¨ë¸ í›ˆë ¨ì— ì–´ë– í•œ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ ì •í™•ë„ë¥¼ ë¹„êµí•˜ì—¬ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "- ê²°ì¸¡ì¹˜ê°€ ìˆì„ ë•Œ, ê²°ì¸¡ì¹˜ë¥¼ ì œê±°í–ˆì„ ë•Œ, ê²°ì¸¡ì¹˜ë¥¼ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´í–ˆì„ ë•Œ ê°ê°ì˜ ê²°ê³¼ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.\n",
    "\n",
    "**3. ì´ìƒì¹˜ê°€ ëª¨ë¸ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ í™•ì¸**\n",
    "- ì´ìƒì¹˜ë¥¼ ì–´ë–¤ ê¸°ì¤€ìœ¼ë¡œ ì •ì˜í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "- ë°ì´í„°ì— ì´ìƒì¹˜ê°€ ìˆì„ ë•Œ ëª¨ë¸ í›ˆë ¨ì— ì–´ë– í•œ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "- ì´ìƒì¹˜ê°€ ìˆì„ ë•Œ, ì´ìƒì¹˜ë¥¼ ì œê±°í–ˆì„ ë•Œ, ì´ìƒì¹˜ë¥¼ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´í–ˆì„ ë•Œ ê°ê°ì˜ ê²°ê³¼ë¥¼ ë¹„êµí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ë°ì´í„° í™•ì¸í•˜ê¸°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# ë‚˜ëˆ”ê³ ë”• í°íŠ¸ ì„¤ì¹˜\n",
    "!apt-get -qq install fonts-nanum\n",
    "\n",
    "# ì„¤ì¹˜ëœ í°íŠ¸ë¥¼ Matplotlibì— ì ìš©\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib as mpl\n",
    "\n",
    "# ë‚˜ëˆ”ê³ ë”• í°íŠ¸ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°\n",
    "font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\n",
    "font_prop = fm.FontProperties(fname=font_path)\n",
    "\n",
    "# Matplotlibì— í°íŠ¸ ì„¤ì •\n",
    "mpl.rc('font', family=font_prop.get_name())\n",
    "\n",
    "# í•œê¸€ ê¹¨ì§ ë°©ì§€ (ìŒìˆ˜ í°íŠ¸ ì„¤ì •)\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# Titanic ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "titanic = sns.load_dataset('titanic')\n",
    "\n",
    "# ê²°ê³¼ê°€ ë¶ˆí•„ìš”í•˜ê²Œ ê¸¸ì–´ì ¸ ì¤‘ìš”í•˜ì§€ ì•Šì€ ì˜¤ë¥˜ ë¬¸êµ¬ë¥¼ ì œê±°í•˜ê¸° ìœ„í•´ ë„£ì€ ì½”ë“œì…ë‹ˆë‹¤.\n",
    "import logging\n",
    "logging.getLogger('matplotlib.font_manager').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 ë°ì´í„° ìš”ì•½í•´ì„œ í™•ì¸í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ë°ì´í„°ì…‹ ê°„ë‹¨íˆ í™•ì¸\n",
    "print(\"ë°ì´í„°ì…‹ì˜ ì²« 5í–‰:\")\n",
    "print(titanic.head())\n",
    "\n",
    "print(\"\\në°ì´í„°ì…‹ ìš”ì•½ ì •ë³´:\")\n",
    "titanic.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# í†µê³„ ìš”ì•½\n",
    "print(\"\\nìˆ˜ì¹˜í˜• ë°ì´í„° í†µê³„ ìš”ì•½:\")\n",
    "print(titanic.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\në²”ì£¼í˜• ë°ì´í„°ì˜ ê³ ìœ ê°’ í™•ì¸:\")\n",
    "for column in titanic.select_dtypes(include=['object', 'category']).columns:\n",
    "    print(f\"{column}ì˜ ê³ ìœ ê°’:\")\n",
    "    print(titanic[column].value_counts())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 ë°ì´í„° ì‹œê°í™”í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 1. ìƒì¡´ ì—¬ë¶€ ë¶„í¬\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(data=titanic, x='survived')\n",
    "plt.title(\"Survival Count (0 = Not Survived, 1 = Survived)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 2. ì„±ë³„ì— ë”°ë¥¸ ìƒì¡´ ì—¬ë¶€\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(data=titanic, x='sex', hue='survived')\n",
    "plt.title(\"Survival Count by Gender\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 3. ë‚˜ì´ ë¶„í¬\n",
    "plt.figure(figsize=(8, 5))\n",
    "# kde : ë°ì´í„°ì˜ ë°€ë„ë¥¼ ì¶”ì •í•˜ëŠ” ê³¡ì„  ì¶”ê°€. bins : êµ¬ê°„ì„ ë‚˜ëˆŒ ê°œìˆ˜\n",
    "sns.histplot(data=titanic, x='age', kde=True, bins=30)\n",
    "plt.title(\"Age Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 4. í´ë˜ìŠ¤ì— ë”°ë¥¸ ìƒì¡´ ì—¬ë¶€\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(data=titanic, x='class', hue='survived')\n",
    "plt.title(\"Survival Count by Passenger Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 5. ìš”ê¸ˆ ë¶„í¬\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.boxplot(data=titanic, x='class', y='fare', hue='survived')\n",
    "plt.title(\"Fare Distribution by Class and Survival\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ê²°ì¸¡ì¹˜ê°€ ëª¨ë¸ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ í™•ì¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 ë°ì´í„° ë‚´ ê²°ì¸¡ì¹˜ í™•ì¸í•˜ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "print(\"=== ê²°ì¸¡ì¹˜ ê°œìˆ˜ í™•ì¸ ===\")\n",
    "missing_data = titanic.isnull().sum()\n",
    "print(missing_data[missing_data > 0])\n",
    "\n",
    "total_missing = titanic.isnull().sum().sum()\n",
    "print(f\"\\nì „ì²´ ë°ì´í„°ì…‹ì—ì„œì˜ ê²°ì¸¡ì¹˜ ê°œìˆ˜: {total_missing}\")\n",
    "\n",
    "missing_per_column = titanic.isnull().sum()\n",
    "print(\"\\nì—´ë³„ ê²°ì¸¡ì¹˜ ê°œìˆ˜:\")\n",
    "print(missing_per_column[missing_per_column > 0])\n",
    "\n",
    "print(\"\\nì—´ë³„ ê²°ì¸¡ì¹˜ ë¹„ìœ¨ (%):\")\n",
    "print((missing_per_column[missing_per_column > 0] / len(titanic) * 100).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ê²°ì¸¡ì¹˜ ì‹œê°í™”í•˜ê¸°\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 6))\n",
    "msno.matrix(titanic)\n",
    "plt.title(\"Missing Values Visualization\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ê·¸ë¦¼ì—ì„œ í°ìƒ‰ ê°€ë¡œ ì„ ì´ ê²°ì¸¡ì¹˜ë¥¼ ì˜ë¯¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 ê²°ì¸¡ì¹˜ ì²˜ë¦¬ - ì œê±°(drop), í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ë°ì´í„° ì „ì²˜ë¦¬\n",
    "def preprocess_data_missing(data, fill_method=None):\n",
    "    df = data.copy()\n",
    "\n",
    "    # ì„±ë³„, íƒ‘ìŠ¹ í•­êµ¬ ë“± ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©\n",
    "    df['sex'] = df['sex'].map({'male': 0, 'female': 1})  # ì„±ë³„ì„ 0ê³¼ 1ë¡œ ë³€í™˜\n",
    "    df['embarked'] = df['embarked'].map({'C': 0, 'Q': 1, 'S': 2})  # íƒ‘ìŠ¹ í•­êµ¬ë¥¼ 0, 1, 2ë¡œ ë³€í™˜\n",
    "    df['embarked'] = df['embarked'].fillna(df['embarked'].mode()[0])  # íƒ‘ìŠ¹ í•­êµ¬ ê²°ì¸¡ê°’ ëŒ€ì²´\n",
    "\n",
    "    # ê²°ì¸¡ê°’ ì²˜ë¦¬ (ì„ íƒì ìœ¼ë¡œ)\n",
    "    if fill_method == 'drop':\n",
    "        df = df.dropna()\n",
    "    elif fill_method == 'mean':\n",
    "        df['age'] = df['age'].fillna(df['age'].mean())\n",
    "        df['fare'] = df['fare'].fillna(df['fare'].mean())\n",
    "    else:\n",
    "        pass  # ê²°ì¸¡ê°’ ìˆëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€\n",
    "\n",
    "    # í•„ìš”í•œ ì»¬ëŸ¼ ì„ íƒ\n",
    "    df = df[['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 ê²°ì¸¡ì¹˜ê°€ ëª¨ë¸ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ - Random Forest\n",
    "- **Random Forest**ëŠ” ì•™ìƒë¸”(Ensemble) í•™ìŠµ ê¸°ë²•ì˜ í•˜ë‚˜ë¡œ, ì—¬ëŸ¬ ê°œì˜ ê²°ì • íŠ¸ë¦¬(Decision Tree)ë¥¼ ê²°í•©í•˜ì—¬ ë” ë‚˜ì€ ì˜ˆì¸¡ ì„±ëŠ¥ì„ ì–»ëŠ” ë°©ë²•ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
    "def random_forest_missing(data):\n",
    "    # 'survived' ì—´ì„ íƒ€ê²Ÿ ë³€ìˆ˜(y)ë¡œ ì„¤ì •í•˜ê³ , ë‚˜ë¨¸ì§€ ì—´ì„ íŠ¹ì„±(X)ìœ¼ë¡œ ì„¤ì •\n",
    "    X = data.drop(columns='survived')  # íƒ€ê²Ÿ ë³€ìˆ˜ 'survived'ë¥¼ ì œì™¸í•œ íŠ¹ì„± ë°ì´í„°\n",
    "    y = data['survived']  # íƒ€ê²Ÿ ë³€ìˆ˜ 'survived' ì„ íƒ\n",
    "\n",
    "    # ë°ì´í„°ë¥¼ í›ˆë ¨ ì„¸íŠ¸ì™€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ë¶„ë¦¬ (í›ˆë ¨ 80%, í…ŒìŠ¤íŠ¸ 20%)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Random Forest ë¶„ë¥˜ê¸° ëª¨ë¸ ìƒì„±\n",
    "    model = RandomForestClassifier(random_state=42)  # ë¬´ì‘ìœ„ì„±ì„ ì œì–´í•˜ê¸° ìœ„í•´ random_state ì„¤ì •\n",
    "    model.fit(X_train, y_train)  # í›ˆë ¨ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ í•™ìŠµ\n",
    "\n",
    "    # í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "    y_pred = model.predict(X_test)  # ëª¨ë¸ë¡œ ì˜ˆì¸¡\n",
    "\n",
    "    # ì˜ˆì¸¡ ê²°ê³¼ì™€ ì‹¤ì œ ê°’(y_test)ì„ ë¹„êµí•˜ì—¬ ì •í™•ë„ ê³„ì‚°\n",
    "    accuracy = accuracy_score(y_test, y_pred)  # ì •í™•ë„ ê³„ì‚°\n",
    "    return accuracy  # ì •í™•ë„ë¥¼ ë°˜í™˜\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê²°ì¸¡ì¹˜ë¥¼ ê·¸ëŒ€ë¡œ ë’€ì„ ë•Œ, ì œê±°í–ˆì„ ë•Œ, í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´í–ˆì„ ë•Œ ì„±ëŠ¥(ì •í™•ë„) ë¹„êµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ê° ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ë°©ë²•ì— ë”°ë¥¸ ì„±ëŠ¥ ë¹„êµ\n",
    "methods = ['original', 'drop', 'mean']\n",
    "results = {}\n",
    "\n",
    "for method in methods:\n",
    "    if method == 'original':\n",
    "        preprocessed_data = preprocess_data_missing(titanic)  # ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì—†ì´\n",
    "    else:\n",
    "        preprocessed_data = preprocess_data_missing(titanic, fill_method=method)\n",
    "\n",
    "    # ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” ë°ì´í„°ëŠ” ì œê±° í›„ ëª¨ë¸ í•™ìŠµ\n",
    "    if method == 'original':\n",
    "        preprocessed_data = preprocessed_data.dropna(subset=['age', 'fare'])\n",
    "\n",
    "    accuracy = random_forest_missing(preprocessed_data)\n",
    "    results[method] = accuracy\n",
    "\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"=== ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ë°©ë²•ì— ë”°ë¥¸ Random Forest ëª¨ë¸ ì„±ëŠ¥ ===\")\n",
    "for method, acc in results.items():\n",
    "    print(f\"{method.capitalize()} ì²˜ë¦¬: Accuracy = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ê²°ì¸¡ì¹˜ë¥¼ ì œê±°í•˜ëŠ” ê²ƒë³´ë‹¤ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´í•  ë•Œ ì˜ˆì¸¡ ì„±ëŠ¥ì´ í–¥ìƒë¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 ê²°ì¸¡ì¹˜ê°€ ëª¨ë¸ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ - Logistic Regression\n",
    "- Logistic Regressionì€ ë°ì´í„°ê°€ ì–´ë–¤ ë²”ì£¼ì— ì†í•  í™•ë¥ ì„ ì •í•˜ê³  ê°€ëŠ¥ì„±ì´ ë” ë†’ì€ ë²”ì£¼ì— ì†í•˜ëŠ” ê²ƒìœ¼ë¡œ ë¶„ë¥˜í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "titanic = sns.load_dataset('titanic')\n",
    "\n",
    "def detect_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)  # 1ë¶„ìœ„ìˆ˜\n",
    "    Q3 = df[column].quantile(0.75)  # 3ë¶„ìœ„ìˆ˜\n",
    "    IQR = Q3 - Q1  # IQR ê³„ì‚°\n",
    "    lower_bound = Q1 - 1.5 * IQR  # í•˜í•œ\n",
    "    upper_bound = Q3 + 1.5 * IQR  # ìƒí•œ\n",
    "    return (df[column] < lower_bound) | (df[column] > upper_bound)\n",
    "\n",
    "\n",
    "def logistic_regression_missing(data):\n",
    "    # 'survived' ì—´ì„ íƒ€ê²Ÿ ë³€ìˆ˜(y)ë¡œ ì„¤ì •í•˜ê³ , ë‚˜ë¨¸ì§€ ì—´ì„ íŠ¹ì„±(X)ìœ¼ë¡œ ì„¤ì •\n",
    "    X = data.drop(columns='survived')  # íƒ€ê²Ÿ ë³€ìˆ˜ 'survived'ë¥¼ ì œì™¸í•œ íŠ¹ì„± ë°ì´í„°\n",
    "    y = data['survived']  # íƒ€ê²Ÿ ë³€ìˆ˜ 'survived' ì„ íƒ\n",
    "\n",
    "    # ë°ì´í„°ë¥¼ í›ˆë ¨ ì„¸íŠ¸ì™€ í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ë¡œ ë¶„ë¦¬ (í›ˆë ¨ 80%, í…ŒìŠ¤íŠ¸ 20%)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Logistic Regression ëª¨ë¸ ìƒì„± (ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ë¥¼ 1000ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ìˆ˜ë ´ì„ ë³´ì¥)\n",
    "    model = LogisticRegression(max_iter=1000, random_state=42)  # ë¬´ì‘ìœ„ì„±ì„ ì œì–´í•˜ê¸° ìœ„í•´ random_state ì„¤ì •\n",
    "    model.fit(X_train, y_train)  # í›ˆë ¨ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ í•™ìŠµ\n",
    "\n",
    "    # í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "    y_pred = model.predict(X_test)  # ëª¨ë¸ë¡œ ì˜ˆì¸¡\n",
    "\n",
    "    # ì˜ˆì¸¡ ê²°ê³¼ì™€ ì‹¤ì œ ê°’(y_test)ì„ ë¹„êµí•˜ì—¬ ì •í™•ë„ ê³„ì‚°\n",
    "    accuracy = accuracy_score(y_test, y_pred)  # ì •í™•ë„ ê³„ì‚°\n",
    "    return accuracy  # ì •í™•ë„ë¥¼ ë°˜í™˜\n",
    "\n",
    "\n",
    "# ê° ê²°ì¸¡ê°’ ì²˜ë¦¬ ë°©ë²•ì— ë”°ë¥¸ ì„±ëŠ¥ ë¹„êµ\n",
    "methods = ['original', 'drop', 'mean']\n",
    "results = {}\n",
    "\n",
    "\n",
    "for method in methods:\n",
    "    if method == 'original':\n",
    "        preprocessed_data = preprocess_data_missing(titanic)  # ê²°ì¸¡ê°’ ì²˜ë¦¬ ì—†ì´\n",
    "    else:\n",
    "        preprocessed_data = preprocess_data_missing(titanic, fill_method=method)\n",
    "\n",
    "    # ê²°ì¸¡ê°’ì´ ìˆëŠ” ë°ì´í„°ëŠ” ì œê±° í›„ ëª¨ë¸ í•™ìŠµ\n",
    "    if method == 'original':\n",
    "        preprocessed_data = preprocessed_data.dropna(subset=['age', 'fare'])\n",
    "\n",
    "    accuracy = logistic_regression_missing(preprocessed_data)\n",
    "    results[method] = accuracy\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"=== ê²°ì¸¡ê°’ ì²˜ë¦¬ ë°©ë²•ì— ë”°ë¥¸ Logistic Regression ëª¨ë¸ ì„±ëŠ¥ ===\")\n",
    "for method, acc in results.items():\n",
    "    print(f\"{method.capitalize()} ì²˜ë¦¬: Accuracy = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ê²°ì¸¡ì¹˜ë¥¼ ì œê±°í•˜ëŠ” ê²ƒë³´ë‹¤ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´í•  ë•Œ ì˜ˆì¸¡ ì„±ëŠ¥ì´ í–¥ìƒë¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ì´ìƒì¹˜ê°€ ëª¨ë¸ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ í™•ì¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 ì´ìƒì¹˜ í™•ì¸\n",
    "\n",
    "**ì´ìƒì¹˜(Outlier)**\n",
    "ë°ì´í„°ì˜ 1ë¶„ìœ„ìˆ˜ë¥¼ Q1, 3ë¶„ìœ„ìˆ˜ë¥¼ Q3ë¼ í•˜ê³  Q3-Q1ì„ IQRì´ë¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "ì´ ë•Œ Q1 - 1.5 * IQRë³´ë‹¤ ë‚®ì€ ê°’ê³¼ Q3 + 1.5 * IQR ë³´ë‹¤ í° ê°’ë“¤ì„ ì´ìƒì¹˜ë¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# age ì»¬ëŸ¼ì˜ ì´ìƒì¹˜ ì‹œê°í™”\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(y='age', data=titanic)\n",
    "plt.title('Age Column Boxplot')\n",
    "plt.show()\n",
    "\n",
    "# IQRì„ ì´ìš©í•œ ì´ìƒì¹˜ íƒì§€\n",
    "Q1 = titanic['age'].quantile(0.25)\n",
    "Q3 = titanic['age'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "outliers = titanic[(titanic['age'] < Q1 - 1.5 * IQR) | (titanic['age'] > Q3 + 1.5 * IQR)]\n",
    "print(f\"\\nage ì»¬ëŸ¼ì—ì„œ ë°œê²¬ëœ ì´ìƒì¹˜ ê°œìˆ˜: {outliers.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 ì´ìƒì¹˜ ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def handle_outliers(df, method):\n",
    "    # 'age'ì™€ 'fare' ì»¬ëŸ¼ì—ì„œ ì´ìƒì¹˜ë¥¼ ì²˜ë¦¬\n",
    "    for column in ['age', 'fare']:  # ìˆ˜ì¹˜í˜• ë³€ìˆ˜ì¸ 'age'ì™€ 'fare'ë§Œ ì²˜ë¦¬\n",
    "        outliers = detect_outliers(df, column)  # 'detect_outliers' í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ìƒì¹˜ ì¸ë±ìŠ¤ íƒì§€\n",
    "        if method == 'remove':  # ì´ìƒì¹˜ë¥¼ ì œê±°í•˜ëŠ” ë°©ë²•\n",
    "            df = df[~outliers]  # ì´ìƒì¹˜ê°€ í¬í•¨ëœ í–‰ì„ ì œê±°\n",
    "        elif method == 'mean':  # ì´ìƒì¹˜ë¥¼ í‰ê· ê°’ìœ¼ë¡œ ëŒ€ì²´í•˜ëŠ” ë°©ë²•\n",
    "            df.loc[outliers, column] = df[column].mean()  # ì´ìƒì¹˜ ê°’ì„ í•´ë‹¹ ì»¬ëŸ¼ì˜ í‰ê· ìœ¼ë¡œ ëŒ€ì²´\n",
    "    return df  # ì´ìƒì¹˜ ì²˜ë¦¬ê°€ ì™„ë£Œëœ ë°ì´í„°í”„ë ˆì„ ë°˜í™˜\n",
    "\n",
    "def preprocess_data_outlier(data, outlier_method=None):\n",
    "    # ë°ì´í„°í”„ë ˆì„ì„ ë³µì‚¬í•˜ì—¬ ì›ë³¸ ë°ì´í„°ë¥¼ ìˆ˜ì •í•˜ì§€ ì•Šë„ë¡ í•¨\n",
    "    df = data.copy()\n",
    "\n",
    "    # ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©\n",
    "    df['sex'] = df['sex'].map({'male': 0, 'female': 1})  # 'male'ì„ 0, 'female'ì„ 1ë¡œ ë§¤í•‘\n",
    "    df['embarked'] = df['embarked'].map({'C': 0, 'Q': 1, 'S': 2})  # 'C', 'Q', 'S'ë¥¼ ê°ê° 0, 1, 2ë¡œ ë§¤í•‘\n",
    "    df['embarked'] = df['embarked'].fillna(df['embarked'].mode()[0])  # 'embarked' ì»¬ëŸ¼ì˜ ê²°ì¸¡ì¹˜ë¥¼ ìµœë¹ˆê°’ìœ¼ë¡œ ì±„ì›€\n",
    "    df['age'] = df['age'].fillna(df['age'].mean())  # 'age' ì»¬ëŸ¼ì˜ ê²°ì¸¡ì¹˜ë¥¼ í‰ê· ê°’ìœ¼ë¡œ ì±„ì›€\n",
    "    df['fare'] = df['fare'].fillna(df['fare'].mean())  # 'fare' ì»¬ëŸ¼ì˜ ê²°ì¸¡ì¹˜ë¥¼ í‰ê· ê°’ìœ¼ë¡œ ì±„ì›€\n",
    "\n",
    "    # ì´ìƒì¹˜ ì²˜ë¦¬ (ì„ íƒì ìœ¼ë¡œ ì²˜ë¦¬)\n",
    "    if outlier_method:\n",
    "        df = handle_outliers(df, method=outlier_method)  # outlier_methodê°€ ì£¼ì–´ì§€ë©´ ì´ìƒì¹˜ ì²˜ë¦¬ í•¨ìˆ˜ í˜¸ì¶œ\n",
    "\n",
    "    # ë¶„ì„ì— ì‚¬ìš©í•  ë³€ìˆ˜ ì„ íƒ\n",
    "    df = df[['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']]  # í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ\n",
    "    return df  # ì „ì²˜ë¦¬ëœ ë°ì´í„°í”„ë ˆì„ ë°˜í™˜\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 ì´ìƒì¹˜ê°€ ëª¨ë¸ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ - Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
    "titanic = sns.load_dataset('titanic')\n",
    "\n",
    "def random_forest_outlier(data):\n",
    "    X = data.drop(columns='survived')\n",
    "    y = data['survived']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return accuracy_score(y_test, y_pred)\n",
    "\n",
    "# ì´ìƒì¹˜ ì²˜ë¦¬ ë°©ë²•ì— ë”°ë¥¸ ì„±ëŠ¥ ë¹„êµ\n",
    "methods = ['original', 'remove', 'mean']\n",
    "results = {}\n",
    "\n",
    "for method in methods:\n",
    "    if method == 'original':\n",
    "        preprocessed_data = preprocess_data_outlier(titanic)  # ì´ìƒì¹˜ ì²˜ë¦¬ ì—†ì´\n",
    "    else:\n",
    "        preprocessed_data = preprocess_data_outlier(titanic, outlier_method=method)\n",
    "\n",
    "    accuracy = random_forest_outlier(preprocessed_data)\n",
    "    results[method] = accuracy\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"=== ì´ìƒì¹˜ ì²˜ë¦¬ ë°©ë²•ì— ë”°ë¥¸ Random Forest ëª¨ë¸ ì„±ëŠ¥ ===\")\n",
    "for method, acc in results.items():\n",
    "    print(f\"{method.capitalize()} ì²˜ë¦¬: Accuracy = {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 ì´ìƒì¹˜ê°€ ëª¨ë¸ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
    "titanic = sns.load_dataset('titanic')\n",
    "\n",
    "def logistic_regression_outlier(data):\n",
    "    X = data.drop(columns='survived')  # ë…ë¦½ ë³€ìˆ˜\n",
    "    y = data['survived']  # ì¢…ì† ë³€ìˆ˜\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Logistic Regression ëª¨ë¸\n",
    "    model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return accuracy\n",
    "\n",
    "# ì´ìƒì¹˜ ì²˜ë¦¬ ë°©ë²•ì— ë”°ë¥¸ ì„±ëŠ¥ ë¹„êµ\n",
    "methods = ['original', 'remove', 'mean']\n",
    "results = {}\n",
    "\n",
    "for method in methods:\n",
    "    if method == 'original':\n",
    "        preprocessed_data = preprocess_data_outlier(titanic)  # ì´ìƒì¹˜ ì²˜ë¦¬ ì—†ì´\n",
    "    else:\n",
    "        preprocessed_data = preprocess_data_outlier(titanic, outlier_method=method)\n",
    "\n",
    "    accuracy = logistic_regression_outlier(preprocessed_data)\n",
    "    results[method] = accuracy\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(\"=== ì´ìƒì¹˜ ì²˜ë¦¬ ë°©ë²•ì— ë”°ë¥¸ Logistic Regression ëª¨ë¸ ì„±ëŠ¥ ===\")\n",
    "for method, acc in results.items():\n",
    "    print(f\"{method.capitalize()} ì²˜ë¦¬: Accuracy = {acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
